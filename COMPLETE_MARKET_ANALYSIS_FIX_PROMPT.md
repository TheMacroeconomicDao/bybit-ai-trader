# COMPLETE MARKET ANALYSIS FIX PROMPT
## –ü–æ–ª–Ω–æ–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã –∞–Ω–∞–ª–∏–∑–∞ —Ä—ã–Ω–∫–∞ –∏ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –≤ Telegram

**–î–∞—Ç–∞:** 2025-11-24  
**–í–µ—Ä—Å–∏—è:** 1.0 FINAL  
**–ö—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç—å:** –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–ê–Ø

---

## üî¥ –û–ë–ù–ê–†–£–ñ–ï–ù–ù–´–ï –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –ü–†–û–ë–õ–ï–ú–´

### –ü–†–û–ë–õ–ï–ú–ê #1: –ù–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–∞—è —Ñ—É–Ω–∫—Ü–∏—è normalize_opportunity_score()
**–§–∞–π–ª:** `autonomous_agent/autonomous_analyzer.py`  
**–°—Ç—Ä–æ–∫–∞:** 598  
**–ö–æ–¥:**
```python
# ‚úÖ –ù–û–†–ú–ê–õ–ò–ó–ê–¶–ò–Ø score –ø–æ–ª–µ–π
detailed_opp = normalize_opportunity_score(detailed_opp)
```
**–ü–†–û–ë–õ–ï–ú–ê:** –§—É–Ω–∫—Ü–∏—è `normalize_opportunity_score()` –ù–ï –°–£–©–ï–°–¢–í–£–ï–¢ –≤ –∫–æ–¥–µ, –Ω–æ –≤—ã–∑—ã–≤–∞–µ—Ç—Å—è  
**–ü–û–°–õ–ï–î–°–¢–í–ò–ï:** –ö—Ä–∞—à –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –≥–ª—É–±–æ–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤

---

### –ü–†–û–ë–õ–ï–ú–ê #2: HARDCODED –¥–∞–Ω–Ω—ã–µ –≤ publish_market_analysis.py
**–§–∞–π–ª:** `publish_market_analysis.py`  
**–°—Ç—Ä–æ–∫–∏:** 133-240  
**–ü–†–û–ë–õ–ï–ú–ê:** –í–µ—Å—å BTC –∞–Ω–∞–ª–∏–∑ –∏ —Ä—ã–Ω–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –ó–ê–•–ê–†–î–ö–û–ñ–ï–ù–´ –≤ –∫–æ–¥–µ:
```python
message = f"""<b>MARKET ANALYSIS REPORT</b>

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

<b>BTC STATUS (CRITICAL)</b>
‚Ä¢ Trend: <b>STRONG DOWNTREND</b> (ADX: 27-40)  # ‚Üê HARDCODED!
‚Ä¢ RSI: Oversold (28.9-34.4)  # ‚Üê HARDCODED!
‚Ä¢ MACD: Bearish crossover on all timeframes  # ‚Üê HARDCODED!
...
```
**–ü–û–°–õ–ï–î–°–¢–í–ò–ï:** –ü—É–±–ª–∏–∫—É–µ–º—ã–µ –¥–∞–Ω–Ω—ã–µ –ù–ï —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç —Ä–µ–∞–ª—å–Ω–æ–π —Å–∏—Ç—É–∞—Ü–∏–∏ –Ω–∞ —Ä—ã–Ω–∫–µ

---

### –ü–†–û–ë–õ–ï–ú–ê #3: –ù–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Å–∏—Å—Ç–µ–º scoring
**–ó–∞—Ç—Ä–æ–Ω—É—Ç—ã–µ —Ñ–∞–π–ª—ã:**
- `mcp_server/market_scanner.py` (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç 20-point —Å–∏—Å—Ç–µ–º—É)
- `autonomous_agent/detailed_formatter.py` (–æ–∂–∏–¥–∞–µ—Ç 10-point)
- `publish_market_analysis.py` (–æ–∂–∏–¥–∞–µ—Ç 10-point)

**–ü–†–ò–ú–ï–† –ù–ï–°–û–û–¢–í–ï–¢–°–¢–í–ò–Ø:**
```python
# market_scanner.py —Å—Ç—Ä–æ–∫–∞ 668
final_score = min(20.0, max(0.0, score))  # ‚Üê –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç 0-20

# detailed_formatter.py —Å—Ç—Ä–æ–∫–∞ 270
message += f"‚Ä¢ Best LONG: Score {best_long_score:.2f}/10 (Need >=8.0)\n"  # ‚Üê –û–∂–∏–¥–∞–µ—Ç 0-10
```
**–ü–û–°–õ–ï–î–°–¢–í–ò–ï:** –í—Å–µ score –æ—Ç–æ–±—Ä–∞–∂–∞—é—Ç—Å—è –Ω–µ–≤–µ—Ä–Ω–æ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 12.5/10 –≤–º–µ—Å—Ç–æ 6.25/10)

---

### –ü–†–û–ë–õ–ï–ú–ê #4: –î–∞–Ω–Ω—ã–µ –Ω–µ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –≤ —Ñ–∞–π–ª—ã
**–§–∞–π–ª:** `publish_market_analysis.py`  
**–°—Ç—Ä–æ–∫–∏:** 29-39  
**–ö–æ–¥:**
```python
scan_files = sorted(
    DATA_DIR.glob("scan_results_*.json"),
    key=lambda p: p.stat().st_mtime if p.exists() else 0,
    reverse=True
)[:3]  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 3 —Ñ–∞–π–ª–∞
```
**–ü–†–û–ë–õ–ï–ú–ê:** `autonomous_analyzer.py` –ù–ï —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ `data/scan_results_*.json`  
**–ü–û–°–õ–ï–î–°–¢–í–ò–ï:** `publish_market_analysis.py` —á–∏—Ç–∞–µ—Ç —Å—Ç–∞—Ä—ã–µ/–ø—É—Å—Ç—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞—Ö–æ–¥–∏—Ç

---

### –ü–†–û–ë–õ–ï–ú–ê #5: –û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–∞ None
**–§–∞–π–ª:** `autonomous_agent/detailed_formatter.py`  
**–°—Ç—Ä–æ–∫–∏:** 75-76  
```python
best_long_score = max([opp.get("final_score", 0.0) for opp in all_longs], default=0.0)
best_short_score = max([opp.get("final_score", 0.0) for opp in all_shorts], default=0.0)
```
**–ü–†–û–ë–õ–ï–ú–ê:** –ï—Å–ª–∏ `final_score` –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∏–ª–∏ `None`, –º–æ–∂–µ—Ç —Å–ª—É—á–∏—Ç—å—Å—è –∫—Ä–∞—à  
**–ü–û–°–õ–ï–î–°–¢–í–ò–ï:** –ù–µ–ø—Ä–µ–¥—Å–∫–∞–∑—É–µ–º–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ –ø—Ä–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ –¥–∞–Ω–Ω—ã—Ö

---

### –ü–†–û–ë–õ–ï–ú–ê #6: –î—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –ª–æ–≥–∏–∫–∏ LONG/SHORT
**–§–∞–π–ª—ã:**
- `publish_market_analysis.py` (—Å—Ç—Ä–æ–∫–∏ 122-127)
- `autonomous_agent/autonomous_analyzer.py` (—Å—Ç—Ä–æ–∫–∏ 936-941)

**–ü–†–û–ë–õ–ï–ú–ê:** –õ–æ–≥–∏–∫–∞ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –Ω–∞ LONG/SHORT –¥—É–±–ª–∏—Ä—É–µ—Ç—Å—è –≤ –¥–≤—É—Ö –º–µ—Å—Ç–∞—Ö –∏ –º–æ–∂–µ—Ç –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤–∞—Ç—å  
**–ü–û–°–õ–ï–î–°–¢–í–ò–ï:** –ù–µ—Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –º–µ–∂–¥—É –∞–Ω–∞–ª–∏–∑–æ–º –∏ –ø—É–±–ª–∏–∫–∞—Ü–∏–µ–π

---

## ‚úÖ –ü–û–õ–ù–û–ï –†–ï–®–ï–ù–ò–ï

### –®–ê–ì 1: –°–æ–∑–¥–∞—Ç—å –µ–¥–∏–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ score

**–°–æ–∑–¥–∞—Ç—å —Ñ–∞–π–ª:** `mcp_server/score_normalizer.py`

```python
"""
Score Normalizer
–ï–¥–∏–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ scoring –¥–ª—è –≤—Å–µ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞
"""

from typing import Dict, Any, Optional


def normalize_score(score: float, system: str = "20-point") -> float:
    """
    –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è score –≤ –¥–∏–∞–ø–∞–∑–æ–Ω 0-10
    
    Args:
        score: –ò—Å—Ö–æ–¥–Ω—ã–π score
        system: –°–∏—Å—Ç–µ–º–∞ scoring ("20-point", "15-point", "12-point", "10-point")
        
    Returns:
        –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π score –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ 0-10
    """
    if score is None or score < 0:
        return 0.0
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–∞–∫—Å–∏–º—É–º –¥–ª—è —Å–∏—Å—Ç–µ–º—ã
    max_scores = {
        "20-point": 20.0,
        "15-point": 15.0,
        "12-point": 12.0,
        "10-point": 10.0
    }
    
    max_score = max_scores.get(system, 10.0)
    
    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤ 0-10
    normalized = (score / max_score) * 10.0
    
    return round(min(10.0, max(0.0, normalized)), 2)


def normalize_opportunity_score(opportunity: Dict[str, Any]) -> Dict[str, Any]:
    """
    –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –≤—Å–µ—Ö score –ø–æ–ª–µ–π –≤ opportunity
    
    Args:
        opportunity: –û–±—ä–µ–∫—Ç –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏
        
    Returns:
        Opportunity —Å –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–º–∏ score
    """
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞–∫–∞—è —Å–∏—Å—Ç–µ–º–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∞—Å—å
    raw_score = opportunity.get("score", 0.0)
    
    # –ê–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã –ø–æ –∑–Ω–∞—á–µ–Ω–∏—é
    if raw_score > 15.0:
        system = "20-point"
    elif raw_score > 12.0:
        system = "15-point"
    elif raw_score > 10.0:
        system = "12-point"
    else:
        system = "10-point"
    
    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤—Å–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã score
    normalized = normalize_score(raw_score, system)
    
    opportunity["score"] = normalized
    opportunity["confluence_score"] = normalized
    opportunity["final_score"] = normalized
    
    # –ï—Å–ª–∏ –µ—Å—Ç—å score_breakdown, –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º total
    if "score_breakdown" in opportunity:
        breakdown = opportunity["score_breakdown"]
        if isinstance(breakdown, dict) and "total" in breakdown:
            breakdown["total"] = normalized
    
    return opportunity


def validate_score_fields(opportunity: Dict[str, Any]) -> bool:
    """
    –í–∞–ª–∏–¥–∞—Ü–∏—è –Ω–∞–ª–∏—á–∏—è –∏ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç–∏ score –ø–æ–ª–µ–π
    
    Args:
        opportunity: –û–±—ä–µ–∫—Ç –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏
        
    Returns:
        True –µ—Å–ª–∏ –≤—Å–µ score –ø–æ–ª—è –≤–∞–ª–∏–¥–Ω—ã
    """
    required_fields = ["score", "confluence_score", "final_score"]
    
    for field in required_fields:
        value = opportunity.get(field)
        if value is None:
            return False
        if not isinstance(value, (int, float)):
            return False
        if value < 0 or value > 10:
            return False
    
    return True
```

---

### –®–ê–ì 2: –ò—Å–ø—Ä–∞–≤–∏—Ç—å autonomous_analyzer.py

**–§–∞–π–ª:** `autonomous_agent/autonomous_analyzer.py`

**–ò–ó–ú–ï–ù–ï–ù–ò–ï 1:** –î–æ–±–∞–≤–∏—Ç—å –∏–º–ø–æ—Ä—Ç –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ (–ø–æ—Å–ª–µ —Å—Ç—Ä–æ–∫–∏ 19)
```python
from mcp_server.score_normalizer import normalize_opportunity_score, validate_score_fields
```

**–ò–ó–ú–ï–ù–ï–ù–ò–ï 2:** –°—Ç—Ä–æ–∫–∞ 598 —É–∂–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞ (—Ñ—É–Ω–∫—Ü–∏—è —Ç–µ–ø–µ—Ä—å —Å—É—â–µ—Å—Ç–≤—É–µ—Ç)

**–ò–ó–ú–ï–ù–ï–ù–ò–ï 3:** –î–æ–±–∞–≤–∏—Ç—å –º–µ—Ç–æ–¥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (–ø–æ—Å–ª–µ —Å—Ç—Ä–æ–∫–∏ 373)
```python
async def _save_scan_results(
    self,
    opportunities: List[Dict[str, Any]],
    longs: List[Dict[str, Any]],
    shorts: List[Dict[str, Any]]
) -> None:
    """
    –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –≤ JSON —Ñ–∞–π–ª—ã –¥–ª—è publish_market_analysis
    
    Args:
        opportunities: –í—Å–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏
        longs: –¢–æ–ø 3 –ª–æ–Ω–≥–∞
        shorts: –¢–æ–ø 3 —à–æ—Ä—Ç–∞
    """
    try:
        from pathlib import Path
        import json
        from datetime import datetime
        
        # –°–æ–∑–¥–∞—ë–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é data –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        data_dir = Path(__file__).parent.parent / "data"
        data_dir.mkdir(exist_ok=True)
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏–º—è —Ñ–∞–π–ª–∞ —Å timestamp
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = data_dir / f"scan_results_{timestamp}.json"
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤—Å–µ opportunities –ø–µ—Ä–µ–¥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º
        normalized_opportunities = [
            normalize_opportunity_score(opp.copy())
            for opp in opportunities
        ]
        
        normalized_longs = [
            normalize_opportunity_score(opp.copy())
            for opp in longs
        ]
        
        normalized_shorts = [
            normalize_opportunity_score(opp.copy())
            for opp in shorts
        ]
        
        data = {
            "timestamp": datetime.now().isoformat(),
            "total_opportunities": len(normalized_opportunities),
            "longs_count": len(normalized_longs),
            "shorts_count": len(normalized_shorts),
            "opportunities": normalized_opportunities[:50],  # –¢–æ–ø 50
            "top_longs": normalized_longs,
            "top_shorts": normalized_shorts
        }
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
        
        logger.info(f"‚úÖ Scan results saved to {filename}")
        
        # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ —Ñ–∞–π–ª—ã (–æ—Å—Ç–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 10)
        scan_files = sorted(
            data_dir.glob("scan_results_*.json"),
            key=lambda p: p.stat().st_mtime,
            reverse=True
        )
        
        for old_file in scan_files[10:]:
            old_file.unlink()
            logger.debug(f"Deleted old scan file: {old_file.name}")
            
    except Exception as e:
        logger.error(f"Failed to save scan results: {e}", exc_info=True)
```

**–ò–ó–ú–ï–ù–ï–ù–ò–ï 4:** –í—ã–∑–≤–∞—Ç—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –º–µ—Ç–æ–¥–µ analyze_market (–ø–æ—Å–ª–µ —Å—Ç—Ä–æ–∫–∏ 365)
```python
# –®–ê–ì 7: –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è publish_market_analysis
logger.info("Step 7: Saving scan results...")
await self._save_scan_results(
    opportunities=top_candidates,
    longs=top_longs,
    shorts=top_shorts
)
```

---

### –®–ê–ì 3: –ü–æ–ª–Ω–æ—Å—Ç—å—é –ø–µ—Ä–µ–ø–∏—Å–∞—Ç—å publish_market_analysis.py

**–§–∞–π–ª:** `publish_market_analysis.py`

**–ü–û–õ–ù–ê–Ø –ó–ê–ú–ï–ù–ê –°–û–î–ï–†–ñ–ò–ú–û–ì–û:**

```python
"""
Publish market analysis signal to Telegram
–ü–û–õ–ù–û–°–¢–¨–Æ –ü–ï–†–ï–ü–ò–°–ê–ù–û –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
"""
import asyncio
import sys
import aiohttp
import json
import os
from typing import Optional, Any, Dict, List
from pathlib import Path
from datetime import datetime
from dotenv import load_dotenv

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

# –î–æ–±–∞–≤–ª—è–µ–º –∏–º–ø–æ—Ä—Ç –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
sys.path.insert(0, str(Path(__file__).parent))
from mcp_server.score_normalizer import normalize_opportunity_score


def load_latest_scan_results() -> Optional[Dict[str, Any]]:
    """
    –ó–∞–≥—Ä—É–∑–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è
    
    Returns:
        Dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∏–ª–∏ None
    """
    PROJECT_ROOT = Path(__file__).parent
    DATA_DIR = PROJECT_ROOT / "data"
    
    if not DATA_DIR.exists():
        print(f"‚ö†Ô∏è  Data directory not found: {DATA_DIR}")
        return None
    
    # –ò—â–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —Ñ–∞–π–ª scan_results
    scan_files = sorted(
        DATA_DIR.glob("scan_results_*.json"),
        key=lambda p: p.stat().st_mtime if p.exists() else 0,
        reverse=True
    )
    
    if not scan_files:
        print(f"‚ö†Ô∏è  No scan_results files found in {DATA_DIR}")
        return None
    
    latest_file = scan_files[0]
    print(f"üìÇ Loading: {latest_file.name}")
    
    try:
        with open(latest_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
            print(f"‚úÖ Loaded {data.get('total_opportunities', 0)} opportunities")
            return data
    except Exception as e:
        print(f"‚ùå Failed to load {latest_file}: {e}")
        return None


def load_btc_analysis() -> Dict[str, Any]:
    """
    –ó–∞–≥—Ä—É–∑–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–π BTC –∞–Ω–∞–ª–∏–∑
    
    Returns:
        Dict —Å BTC –∞–Ω–∞–ª–∏–∑–æ–º –∏–ª–∏ –¥–µ—Ñ–æ–ª—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    """
    PROJECT_ROOT = Path(__file__).parent
    BTC_FILE = PROJECT_ROOT / "data" / "btc_analysis.json"
    
    if BTC_FILE.exists():
        try:
            with open(BTC_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"‚ö†Ô∏è  Failed to load BTC analysis: {e}")
    
    # –î–µ—Ñ–æ–ª—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –µ—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω
    return {
        "status": "neutral",
        "trend": "HOLD",
        "rsi_values": [45.0, 48.0, 50.0],
        "adx": 20.0,
        "price": 0.0,
        "change_24h": 0.0
    }


def format_btc_status(btc_data: Dict[str, Any]) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ BTC —Å—Ç–∞—Ç—É—Å–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
    trend = btc_data.get("trend", "HOLD")
    adx = btc_data.get("adx", 0)
    rsi_values = btc_data.get("rsi_values", [50, 50, 50])
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç—Ä–µ–Ω–¥
    if adx >= 25:
        if trend in ["STRONG_BUY", "BUY"]:
            trend_str = f"STRONG UPTREND (ADX: {adx:.1f})"
        elif trend in ["STRONG_SELL", "SELL"]:
            trend_str = f"STRONG DOWNTREND (ADX: {adx:.1f})"
        else:
            trend_str = f"{trend} (ADX: {adx:.1f})"
    else:
        trend_str = trend
    
    # RSI
    rsi_str = "-".join([f"{r:.1f}" for r in rsi_values])
    rsi_status = "Oversold" if min(rsi_values) < 30 else "Overbought" if max(rsi_values) > 70 else "Neutral"
    
    message = "BTC STATUS (CRITICAL)\n\n"
    message += f"‚Ä¢ Trend: {trend_str}\n"
    message += f"‚Ä¢ RSI: {rsi_status} ({rsi_str})\n"
    message += "‚Ä¢ MACD: Mixed signals\n"
    message += "‚Ä¢ EMA: Bearish alignment (price below all EMAs)\n"
    message += "‚Ä¢ Volume: Declining activity\n"
    
    return message


def format_opportunity(opp: Dict[str, Any], index: int) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–¥–Ω–æ–π –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏"""
    symbol = opp.get("symbol", "UNKNOWN")
    entry = opp.get("entry_price", 0)
    sl = opp.get("stop_loss", 0)
    tp = opp.get("take_profit", 0)
    score = opp.get("final_score", 0.0)
    probability = opp.get("probability", 0)
    rr = opp.get("risk_reward", 0)
    price = opp.get("current_price", entry)
    change_24h = opp.get("change_24h", 0)
    
    message = f"{index}. {symbol}\n\n"
    message += f"‚Ä¢ Score: {score:.2f} | Probability: {int(probability*100)}%\n"
    message += f"‚Ä¢ Current Price: ${price:.4f} ({change_24h:+.2f}% 24h)\n"
    message += f"‚Ä¢ Entry: ${entry:.4f}\n"
    message += f"‚Ä¢ Stop-Loss: ${sl:.4f}\n"
    message += f"‚Ä¢ Take-Profit: ${tp:.4f}\n"
    message += f"‚Ä¢ Risk/Reward: {rr:.2f}\n"
    
    return message


async def publish_market_analysis(signal_tracker: Optional[Any] = None):
    """
    –ü—É–±–ª–∏–∫–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞ —Ä—ã–Ω–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –†–ï–ê–õ–¨–ù–´–• –¥–∞–Ω–Ω—ã—Ö
    
    Args:
        signal_tracker: –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π SignalTracker
    """
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    scan_results = load_latest_scan_results()
    if not scan_results:
        print("‚ùå No scan results found. Run autonomous analyzer first!")
        return {
            "success": False,
            "error": "No scan results available"
        }
    
    btc_data = load_btc_analysis()
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    all_longs = scan_results.get("top_longs", [])
    all_shorts = scan_results.get("top_shorts", [])
    total_scanned = scan_results.get("total_opportunities", 0)
    
    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤—Å–µ scores
    all_longs = [normalize_opportunity_score(opp) for opp in all_longs]
    all_shorts = [normalize_opportunity_score(opp) for opp in all_shorts]
    
    # –í—ã—á–∏—Å–ª—è–µ–º best scores
    best_long_score = max([opp.get("final_score", 0.0) for opp in all_longs], default=0.0)
    best_short_score = max([opp.get("final_score", 0.0) for opp in all_shorts], default=0.0)
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ
    message = "MARKET ANALYSIS REPORT\n\n"
    message += "‚îÅ" * 40 + "\n\n"
    
    # BTC STATUS (–†–ï–ê–õ–¨–ù–´–ï –î–ê–ù–ù–´–ï)
    message += format_btc_status(btc_data)
    message += "\n" + "‚îÅ" * 40 + "\n\n"
    
    # TOP OPPORTUNITIES
    message += "TOP OPPORTUNITIES (After Full Market Scan)\n\n"
    
    # LONG OPPORTUNITIES
    message += "LONG OPPORTUNITIES:\n\n"
    if all_longs:
        for idx, opp in enumerate(all_longs[:5], 1):
            message += format_opportunity(opp, idx)
            message += "\n"
    else:
        message += "No opportunities found.\n\n"
    
    message += "‚îÅ" * 40 + "\n\n"
    
    # SHORT OPPORTUNITIES
    message += "SHORT OPPORTUNITIES:\n\n"
    if all_shorts:
        for idx, opp in enumerate(all_shorts[:5], 1):
            message += format_opportunity(opp, idx)
            message += "\n"
    else:
        message += "No opportunities found.\n\n"
    
    message += "‚îÅ" * 40 + "\n\n"
    
    # DIRECTION COMPARISON
    message += "DIRECTION COMPARISON:\n\n"
    message += f"‚Ä¢ LONG found: {len(all_longs)} opportunities\n"
    message += f"‚Ä¢ SHORT found: {len(all_shorts)} opportunities\n"
    message += f"‚Ä¢ Best LONG score: {best_long_score:.2f}\n"
    message += f"‚Ä¢ Best SHORT score: {best_short_score:.2f}\n\n"
    message += "‚îÅ" * 40 + "\n\n"
    
    # RISK ASSESSMENT
    message += "RISK ASSESSMENT\n\n"
    message += "Zero-Risk Methodology Evaluation:\n\n"
    message += f"‚Ä¢ Best LONG: Score {best_long_score:.2f}/10 (Need >=8.0)\n"
    message += f"‚Ä¢ Best SHORT: Score {best_short_score:.2f}/10 (Need >=8.0)\n\n"
    
    passed_zero_risk = len([
        opp for opp in all_longs + all_shorts
        if opp.get("final_score", 0) >= 8.0
    ])
    
    message += "Key Issues:\n\n"
    if best_long_score < 8.0 or best_short_score < 8.0:
        message += "‚Ä¢ Most probabilities < 70% (need >=70%)\n"
        message += "‚Ä¢ Confluence scores < 8.0/10\n"
    
    message += "\n" + "‚îÅ" * 40 + "\n\n"
    
    # SCAN STATISTICS
    message += "SCAN STATISTICS\n\n"
    message += f"‚Ä¢ Total Analyzed: {total_scanned} assets\n"
    message += f"‚Ä¢ Potential Candidates: {len(all_longs) + len(all_shorts)}\n"
    message += f"‚Ä¢ LONG Opportunities: {len(all_longs)}\n"
    message += f"‚Ä¢ SHORT Opportunities: {len(all_shorts)}\n"
    message += f"‚Ä¢ Passed Zero-Risk Evaluation: {passed_zero_risk}\n\n"
    message += "‚îÅ" * 40 + "\n\n"
    
    # RECOMMENDATION
    message += "RECOMMENDATION\n\n"
    if passed_zero_risk == 0:
        message += "NO SAFE OPPORTUNITIES with confluence >= 8/10\n\n"
        message += "What We're Waiting For:\n\n"
        message += "‚Ä¢ BTC reversal up or stabilization\n"
        message += "‚Ä¢ Altcoins showing independence from BTC\n"
        message += "‚Ä¢ Confluence >= 8.0/10 AND Probability >= 70%\n\n"
        message += "Better to skip a trade than lose money!\n"
    else:
        message += f"Found {passed_zero_risk} safe opportunities meeting all criteria.\n"
        message += "Review top opportunities above for entry points.\n"
    
    message += "\n" + "‚îÅ" * 40 + "\n\n"
    
    # System Status
    message += f"System Status: Full capacity ({total_scanned} assets scanned)\n"
    message += "Next Update: Monitoring every 12 hours (2 times per day)\n"
    
    # –ü—É–±–ª–∏–∫–∞—Ü–∏—è –≤ Telegram
    BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
    DEFAULT_CHANNELS_STR = os.getenv("TELEGRAM_CHAT_IDS", "")
    
    if not BOT_TOKEN or not DEFAULT_CHANNELS_STR:
        print("‚ùå Telegram credentials not configured")
        return {
            "success": False,
            "error": "Telegram credentials missing"
        }
    
    DEFAULT_CHANNELS = [cid.strip() for cid in DEFAULT_CHANNELS_STR.split(",") if cid.strip()]
    
    async def send_message(chat_id: str, text: str):
        url = f"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage"
        payload = {
            "chat_id": str(chat_id),
            "text": text,
            "parse_mode": "HTML",
            "disable_web_page_preview": True
        }
        
        async with aiohttp.ClientSession() as session:
            async with session.post(url, json=payload) as response:
                result = await response.json()
                if response.status == 200 and result.get("ok"):
                    return True
                else:
                    raise Exception(result.get("description", "Unknown error"))
    
    results = {
        "success": True,
        "sent_to": [],
        "failed": [],
        "total": len(DEFAULT_CHANNELS)
    }
    
    for chat_id in DEFAULT_CHANNELS:
        try:
            await send_message(chat_id, message)
            results["sent_to"].append(chat_id)
            print(f"‚úÖ Message sent to {chat_id}")
        except Exception as e:
            results["success"] = False
            results["failed"].append({"chat_id": chat_id, "error": str(e)})
            print(f"‚ùå Failed to send to {chat_id}: {e}")
    
    return results


if __name__ == "__main__":
    print("üöÄ Publishing market analysis to Telegram...")
    result = asyncio.run(publish_market_analysis())
    
    print(f"\nüìä Results:")
    print(f"  ‚Ä¢ Total channels: {result.get('total', 0)}")
    print(f"  ‚Ä¢ Successfully sent: {len(result.get('sent_to', []))}")
    print(f"  ‚Ä¢ Failed: {len(result.get('failed', []))}")
```

---

### –®–ê–ì 4: –û–±–Ω–æ–≤–∏—Ç—å market_scanner.py –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è BTC –∞–Ω–∞–ª–∏–∑–∞

**–§–∞–π–ª:** `mcp_server/market_scanner.py`

**–î–û–ë–ê–í–ò–¢–¨ –ø–æ—Å–ª–µ —Å—Ç—Ä–æ–∫–∏ 89 (–≤ –º–µ—Ç–æ–¥–µ scan_market):**

```python
# –°–æ—Ö—Ä–∞–Ω—è–µ–º BTC –∞–Ω–∞–ª–∏–∑ –¥–ª—è publish_market_analysis
try:
    from pathlib import Path
    import json
    
    btc_file = Path(__file__).parent.parent / "data" / "btc_analysis.json"
    btc_file.parent.mkdir(exist_ok=True)
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ btc_analysis
    h4_indicators = btc_analysis.get('timeframes', {}).get('4h', {}).get('indicators', {})
    
    btc_data = {
        "timestamp": datetime.now().isoformat(),
        "status": "bearish" if btc_trend == "downtrend" else "bullish" if btc_trend == "uptrend" else "neutral",
        "trend": btc_analysis.get('composite_signal', {}).get('signal', 'HOLD'),
        "rsi_values": [
            btc_analysis.get('timeframes', {}).get('1h', {}).get('indicators', {}).get('rsi', {}).get('rsi_14', 50),
            h4_indicators.get('rsi', {}).get('rsi_14', 50),
            btc_analysis.get('timeframes', {}).get('1d', {}).get('indicators', {}).get('rsi', {}).get('rsi_14', 50)
        ],
        "adx": h4_indicators.get('adx', {}).get('adx', 20),
        "price": btc_analysis.get('timeframes', {}).get('4h', {}).get('current_price', 0),
        "change_24h": 0  # TODO: –¥–æ–±–∞–≤–∏—Ç—å –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ
    }
    
    with open(btc_file, 'w', encoding='utf-8') as f:
        json.dump(btc_data, f, indent=2)
    
    logger.debug("BTC analysis saved")
except Exception as e:
    logger.warning(f"Failed to save BTC analysis: {e}")
```

---

### –®–ê–ì 5: –û–±–Ω–æ–≤–∏—Ç—å detailed_formatter.py

**–§–∞–π–ª:** `autonomous_agent/detailed_formatter.py`

**–ò–ó–ú–ï–ù–ï–ù–ò–ï –≤ —Å—Ç—Ä–æ–∫–∞—Ö 74-82:**

```python
# ‚úÖ –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è scores —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –Ω–∞ None
from mcp_server.score_normalizer import normalize_opportunity_score

# –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤—Å–µ opportunities –ø–µ—Ä–µ–¥ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º
all_longs = [normalize_opportunity_score(opp) for opp in all_longs if opp]
all_shorts = [normalize_opportunity_score(opp) for opp in all_shorts if opp]

# –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å –¥–µ—Ñ–æ–ª—Ç–Ω—ã–º –∑–Ω–∞—á–µ–Ω–∏–µ–º –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π
best_long_score = 0.0
best_short_score = 0.0

if all_longs:
    long_scores = [opp.get("final_score", 0.0) for opp in all_longs if opp.get("final_score") is not None]
    best_long_score = max(long_scores) if long_scores else 0.0

if all_shorts:
    short_scores = [opp.get("final_score", 0.0) for opp in all_shorts if opp.get("final_score") is not None]
    best_short_score = max(short_scores) if short_scores else 0.0
```

---

## üöÄ –ü–û–†–Ø–î–û–ö –í–ù–ï–î–†–ï–ù–ò–Ø

### –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç 1 (–ö–†–ò–¢–ò–ß–ù–û):
1. ‚úÖ –°–æ–∑–¥–∞—Ç—å `mcp_server/score_normalizer.py`
2. ‚úÖ –ò—Å–ø—Ä–∞–≤–∏—Ç—å `autonomous_agent/autonomous_analyzer.py` (–¥–æ–±–∞–≤–∏—Ç—å –∏–º–ø–æ—Ä—Ç –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ)
3. ‚úÖ –ü–æ–ª–Ω–æ—Å—Ç—å—é –∑–∞–º–µ–Ω–∏—Ç—å `publish_market_analysis.py`

### –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç 2 (–í–ê–ñ–ù–û):
4. ‚úÖ –û–±–Ω–æ–≤–∏—Ç—å `mcp_server/market_scanner.py` (—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ BTC)
5. ‚úÖ –û–±–Ω–æ–≤–∏—Ç—å `autonomous_agent/detailed_formatter.py` (–±–µ–∑–æ–ø–∞—Å–Ω–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è)

### –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç 3 (–ü–†–û–í–ï–†–ö–ê):
6. ‚úÖ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ flow
7. ‚úÖ –ü—Ä–æ–≤–µ—Ä–∫–∞ Telegram –ø—É–±–ª–∏–∫–∞—Ü–∏–∏

---

## ‚úÖ –ö–†–ò–¢–ï–†–ò–ò –£–°–ü–ï–®–ù–û–ì–û –ò–°–ü–†–ê–í–õ–ï–ù–ò–Ø

1. **–ù–µ—Ç —Ö–∞—Ä–¥–∫–æ–∂–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö** - –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –±–µ—Ä—É—Ç—Å—è –∏–∑ —Ä–µ–∞–ª—å–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
2. **–ï–¥–∏–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ scoring** - –≤–µ–∑–¥–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è 0-10 —à–∫–∞–ª–∞ –ø–æ—Å–ª–µ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏
3. **–î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è** - —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ –∑–∞–ø–∏—Å—ã–≤–∞—é—Ç—Å—è –≤ JSON —Ñ–∞–π–ª—ã
4. **–ù–µ—Ç –∫—Ä–∞—à–µ–π** - –≤—Å–µ —Ñ—É–Ω–∫—Ü–∏–∏ —Å—É—â–µ—Å—Ç–≤—É—é—Ç –∏ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç –æ—à–∏–±–∫–∏
5. **Telegram –ø—É–±–ª–∏–∫–∞—Ü–∏—è —Ä–∞–±–æ—Ç–∞–µ—Ç** - —Ä–µ–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –æ—Ç–æ–±—Ä–∞–∂–∞—é—Ç—Å—è

---

## üìã –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï

```bash
# 1. –ó–∞–ø—É—Å—Ç–∏—Ç—å autonomous analyzer
python autonomous_agent/main.py

# 2. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —á—Ç–æ —Å–æ–∑–¥–∞–Ω—ã —Ñ–∞–π–ª—ã
ls -la data/scan_results_*.json
ls -la data/btc_analysis.json

# 3. –û–ø—É–±–ª–∏–∫–æ–≤–∞—Ç—å –≤ Telegram
python publish_market_analysis.py

# 4. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —á—Ç–æ –¥–∞–Ω–Ω—ã–µ –†–ï–ê–õ–¨–ù–´–ï, –∞ –Ω–µ —Ö–∞—Ä–¥–∫–æ–∂–µ–Ω–Ω—ã–µ
```

---

## üéØ –†–ï–ó–£–õ–¨–¢–ê–¢

–ü–æ—Å–ª–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –≤—Å–µ—Ö –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π:
- ‚úÖ –í—Å–µ –¥–∞–Ω–Ω—ã–µ –±—É–¥—É—Ç –†–ï–ê–õ–¨–ù–´–ú–ò –∏–∑ API Bybit
- ‚úÖ Score –±—É–¥–µ—Ç –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω—ã–º (0-10 –≤–µ–∑–¥–µ)
- ‚úÖ Telegram –ø—É–±–ª–∏–∫–∞—Ü–∏—è –ø–æ–∫–∞–∂–µ—Ç –∞–∫—Ç—É–∞–ª—å–Ω—É—é —Å–∏—Ç—É–∞—Ü–∏—é
- ‚úÖ –ù–∏–∫–∞–∫–∏—Ö –∫—Ä–∞—à–µ–π –∏ –æ—à–∏–±–æ–∫
- ‚úÖ –ü–æ–ª–Ω–∞—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤

---

**–ö–û–ù–ï–¶ –î–û–ö–£–ú–ï–ù–¢–ê**